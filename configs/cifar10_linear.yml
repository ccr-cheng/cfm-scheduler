train:
  seed: 42
  max_iter: 100000
  batch_size: 512
  log_freq: 50
  val_freq: 500
  save_freq: 5000
  max_grad_norm: 100.
  valid_max_batch: 32
  optimizer:
    type: adam
    lr: 3.e-4
    weight_decay: 0.
    beta1: 0.9
    beta2: 0.999
  scheduler:
    type: plateau
    factor: 0.5
    patience: 10
    min_lr: 1.e-4

datasets:
  train:
    type: cifar10
    root: ./data/cifar10
    download: true
    transform:
      - type: to_tensor
      - type: random_horizontal_flip
        p: 0.5
  test:
    type: cifar10
    root: ./data/cifar10
    download: true
    transform:
      - type: to_tensor

model:
  max_t: 0.99
  data_dims: [ 3, 32, 32 ]
scheduler:
  type: linear
encoder:
  in_channels: 3
  normalization: InstanceNorm++
  ngf: 128
  nonlinearity: elu

n_sample: 64
n_step: 200
